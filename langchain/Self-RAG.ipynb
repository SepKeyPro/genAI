{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMMr/h6pwVk6UuDwMsgyyOz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install langchain-core langchain langgraph langchain-community langchain-openai pypdf langchainhub chromadb pypdf"],"metadata":{"id":"gDmb89lbm5D7","executionInfo":{"status":"ok","timestamp":1720206023461,"user_tz":240,"elapsed":280,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"LfuvaxBNmVy7","executionInfo":{"status":"ok","timestamp":1720206147609,"user_tz":240,"elapsed":11469,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}}},"outputs":[],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_community.document_loaders import PyPDFLoader\n","from langchain_community.vectorstores import Chroma\n","from langchain_openai import OpenAIEmbeddings\n","from google.colab import userdata\n","api_key = userdata.get(\"OPENAI\")\n","\n","pdfs = [\n","    \"../docs/us_states_info.pdf\",\n","    \"../docs/canada_provinces_info.pdf\",\n","]\n","\n","docs = [PyPDFLoader(pdf).load() for pdf in pdfs]\n","docs_list = [item for sublist in docs for item in sublist]\n","\n","text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=250, chunk_overlap=0)\n","docs_splits = text_splitter.split_documents(docs_list)\n","# Add to vectorDB\n","vectorstore = Chroma.from_documents(\n","    documents=docs_splits,\n","    collection_name=\"rag-chroma\",\n","    embedding=OpenAIEmbeddings(api_key=api_key),\n",")\n","retriever = vectorstore.as_retriever()"]},{"cell_type":"code","source":["# Retrival grader\n","\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain_openai import ChatOpenAI\n","\n","class GradeDocument(BaseModel):\n","  binary_score: str = Field(description=\"Documents are relevant to the question, 'yes' or 'no'\")\n","\n","\n","# LLM with function call\n","llm = ChatOpenAI(api_key=api_key, model=\"gpt-4\", temperature=0)\n","structured_llm_grader = llm.with_structured_output(GradeDocument)\n","\n","# Prompt\n","system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n","    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n","    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n","    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n","grade_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", system),\n","        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n","    ]\n",")\n","\n","retrival_grader = grade_prompt | structured_llm_grader\n","\n"],"metadata":{"id":"jmkUkUOqrsDd","executionInfo":{"status":"ok","timestamp":1720206156289,"user_tz":240,"elapsed":820,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["from langchain import hub\n","from langchain_core.output_parsers import StrOutputParser\n","\n","rag_prompt = hub.pull(\"rlm/rag-prompt\")\n","llm = ChatOpenAI(api_key=api_key, model=\"gpt-4\", temperature=0)\n","\n","rag_chain = rag_prompt | llm | StrOutputParser()"],"metadata":{"id":"3vP0e4tYwWO4","executionInfo":{"status":"ok","timestamp":1720206226221,"user_tz":240,"elapsed":687,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Hallucination Grader\n","\n","class HallucinationGrade(BaseModel):\n","  binary_score: str = Field(description=\"Model hallucinated in answering the question, 'yes' or 'no'\")\n","\n","# LLM with function call\n","llm = ChatOpenAI(api_key=api_key, model=\"gpt-4\", temperature=0)\n","structured_llm_grader = llm.with_structured_output(HallucinationGrade)\n","system = \"\"\"You are assessing the generation based on the facts provided in the documents. \\n\n","         Assess the generated answer. If the answer is grounded in the facts given in the documents say 'No', otherwise say 'Yes'\n","        \"\"\"\n","hallucination_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", system),\n","        (\"human\", \"Retrieved documents: \\n\\n {documents} \\n\\n generated answer: {generation}\"),\n","    ])\n","\n","hallucination_grader = hallucination_prompt | structured_llm_grader"],"metadata":{"id":"nZIMfGiS478u","executionInfo":{"status":"ok","timestamp":1720206270861,"user_tz":240,"elapsed":304,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Answer Grader\n","\n","class AnswerGrade(BaseModel):\n","  binary_score: str = Field(description=\"Model answer is correct, 'yes' or 'no'\")\n","\n","# LLM with function call\n","llm = ChatOpenAI(api_key=api_key, model=\"gpt-4\", temperature=0)\n","structured_llm_grader = llm.with_structured_output(AnswerGrade)\n","system = \"\"\"You are assessing the generated answer. \\n\n","         Assess the generated answer. If the answer addresses the question correctly say 'Yes', otherwise say 'No'.\n","        \"\"\"\n","answer_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", system),\n","        (\"human\", \"generated answer: {generation} \\n\\n question: {question}\"),\n","    ])\n","\n","answer_grader = answer_prompt | structured_llm_grader"],"metadata":{"id":"9uS2hM1Q9-Yn","executionInfo":{"status":"ok","timestamp":1720206274125,"user_tz":240,"elapsed":588,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def retrive_docs(state):\n","  question = state[\"question\"]\n","  docs = retriever.get_relevant_documents(question)\n","  print(\"Retriving documents\")\n","  return {'docs': docs, 'question': question}"],"metadata":{"id":"ZYmQJ22K3SZ1","executionInfo":{"status":"ok","timestamp":1720206280817,"user_tz":240,"elapsed":532,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def grade_documents(state):\n","  question = state[\"question\"]\n","  docs = state[\"docs\"]\n","  generation = state[\"generation\"]\n","  filtered_docs = []\n","  for doc in docs:\n","    grade = retrival_grader.invoke({\"question\": question, \"document\": doc})\n","    if grade.binary_score == \"yes\":\n","      print(\"Doc is relevant, adding to filtered docs list\")\n","      filtered_docs.append(doc)\n","    else:\n","      print(\"Doc is not relevant, going to the next one\")\n","      pass\n","  return {'docs': filtered_docs, 'question': question}"],"metadata":{"id":"_41L0fcCGmT8","executionInfo":{"status":"ok","timestamp":1720206284159,"user_tz":240,"elapsed":595,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def generate(state):\n","  question = state[\"question\"]\n","  docs = state[\"docs\"]\n","  print(\"Generating answer\")\n","  generation = rag_chain.invoke({\"question\": question, \"context\": docs})\n","  return {'generation': generation, 'question': question}"],"metadata":{"id":"vToZIlhXECLB","executionInfo":{"status":"ok","timestamp":1720206287381,"user_tz":240,"elapsed":702,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def decide_to_generate(state):\n","  question = state[\"question\"]\n","  filtered_docs = state[\"docs\"]\n","  if not filtered_docs:\n","    print(\"No relevant doc\")\n","    return 'not_useful'\n","  else:\n","    return 'generate'"],"metadata":{"id":"hJw0ZE2fKASR","executionInfo":{"status":"ok","timestamp":1720206289901,"user_tz":240,"elapsed":589,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def grade_generation_v_documents_and_question(state):\n","  question = state[\"question\"]\n","  docs = state[\"docs\"]\n","  generation = state[\"generation\"]\n","  hall_grade = hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})\n","  if hall_grade.binary_score == \"No\":\n","    answer_grade = answer_grader.invoke({\"generation\": generation, \"question\": question})\n","    if answer_grade.binary_score == \"Yes\":\n","      return 'useful'\n","    else:\n","      return 'not_useful'\n","  else:\n","    return 'not_supported'"],"metadata":{"id":"6-l1nFNPOu5h","executionInfo":{"status":"ok","timestamp":1720206292412,"user_tz":240,"elapsed":324,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["# Graph\n","\n","<center><figure><img src=\"../imgs/self-rag.png\" alt=\"drawing\" width=\"1100\"/><figcaption>Fig. 1: Graph diagram</figcaption></figure></center>"],"metadata":{"id":"SaG6xmVHFG1S"}},{"cell_type":"code","source":["from typing import List, TypedDict\n","\n","class GraphSate(TypedDict):\n","  question: str\n","  docs: List[str]\n","  generation: str\n","\n"],"metadata":{"id":"Vdp2xBgvAOZ5","executionInfo":{"status":"ok","timestamp":1720206296005,"user_tz":240,"elapsed":568,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["from langgraph.graph import END, StateGraph, START\n","\n","workflow = StateGraph(GraphSate)\n","workflow.add_node('retrive', retrive_docs)\n","workflow.add_node('generate', generate)\n","workflow.add_node('grade_documents', grade_documents)\n","\n","workflow.add_edge(START, 'retrive')\n","workflow.add_edge('retrive', 'grade_documents')\n","workflow.add_conditional_edges(\n","    'grade_documents',\n","    decide_to_generate,\n","    {\n","        \"not_useful\": END,\n","        \"generate\": \"generate\",\n","    },\n",")\n","\n","workflow.add_conditional_edges(\n","    'generate',\n","    grade_generation_v_documents_and_question,\n","    {\n","        \"not_supported\": \"generate\",\n","        \"not_useful\": END,\n","        \"useful\": END,\n","    },\n",")\n","\n","app = workflow.compile()"],"metadata":{"id":"s1XeFHsBPXd5","executionInfo":{"status":"ok","timestamp":1720206298710,"user_tz":240,"elapsed":390,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["# Output\n","\n","Try with non-relevant question to our index."],"metadata":{"id":"VRnktitxCtC0"}},{"cell_type":"code","source":["from pprint import pprint\n","\n","# Run\n","inputs = {\"question\": \"What is agent memory?\"}\n","for output in app.stream(inputs):\n","    for key, value in output.items():\n","        # Node\n","        pprint(f\"Node '{key}':\")\n","        # Optional: print full state at each node\n","        # pprint(f\"value: {value}\")\n","    pprint(\"\\n---\\n\")\n","# Final generation\n","response = value.get('generation')\n","if response is None:\n","    print(\"Couldn't generate a uselful answer\")\n","else:\n","    pprint(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T9Ocr-XzrfsL","executionInfo":{"status":"ok","timestamp":1720206307286,"user_tz":240,"elapsed":4935,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}},"outputId":"728f51ee-c9c1-4d62-fe58-cdc4e9fcc9e0"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Retriving documents\n","\"Node 'retrive':\"\n","'\\n---\\n'\n","Doc is not relevant, going to the next one\n","Doc is not relevant, going to the next one\n","Doc is not relevant, going to the next one\n","Doc is not relevant, going to the next one\n","No relevant doc\n","\"Node 'grade_documents':\"\n","'\\n---\\n'\n","Couldn't generate a uselful answer\n"]}]},{"cell_type":"markdown","source":["Try with a relevant question to our index"],"metadata":{"id":"T4y1Wl9GDgn3"}},{"cell_type":"code","source":["# Run\n","inputs = {\"question\": \"What is life in Ontorio like??\"}\n","for output in app.stream(inputs):\n","    for key, value in output.items():\n","        # Node\n","        pprint(f\"Node '{key}':\")\n","        # Optional: print full state at each node\n","        # pprint(f\"value: {value}\")\n","    pprint(\"\\n---\\n\")\n","# Final generation\n","response = value.get('generation')\n","if response is None:\n","    print(\"Couldn't generate a uselful answer\")\n","else:\n","    pprint(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KAmvr64-Dnjv","executionInfo":{"status":"ok","timestamp":1720206497737,"user_tz":240,"elapsed":9332,"user":{"displayName":"sepehr keykhaie","userId":"18194880490269398179"}},"outputId":"bf4cf5ba-b119-407a-b6dd-c6cd72eca34e"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Retriving documents\n","\"Node 'retrive':\"\n","'\\n---\\n'\n","Doc is relevant, adding to filtered docs list\n","Doc is not relevant, going to the next one\n","Doc is not relevant, going to the next one\n","Doc is not relevant, going to the next one\n","\"Node 'grade_documents':\"\n","'\\n---\\n'\n","Generating answer\n","\"Node 'generate':\"\n","'\\n---\\n'\n","('Life in Ontario, Canada is characterized by a humid continental climate with '\n"," 'hot summers and cold winters. It has a diverse cultural heritage with '\n"," 'influences from around the world, and is known for arts, music, and sports. '\n"," 'The cost of living is high, particularly in Toronto.')\n"]}]}]}