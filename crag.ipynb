{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e36c551b-594b-4233-85d6-0af199b5df99",
   "metadata": {},
   "source": [
    "# Corrective Retrieval Augmented Generation (CRAG)\n",
    "\n",
    "Corrective-RAG (CRAG) is a recent paper that introduces an interesting approach for self-reflective RAG. You can read the paper [here](https://arxiv.org/pdf/2401.15884.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d0f13-5264-46c7-a4a3-e606adbd00ca",
   "metadata": {},
   "source": [
    "retrieval augmented generation (RAG) has introduced a retrieval technique to incorporate relevant knowledge to the model's input therefore improving output generation. Within this framework, models receive augmented input by adding relevant documents retrieved from an external knowledge collections. While RAG serves as a practicable complement to LLMs, its effectiveness is contingent upon the relevance and accuracy of the retrieved documents. The heavy reliance of generation on the retrieved knowledge raises significant concerns about the modelâ€™s behavior and performance in scenarios where retrieval may fail or return inaccurate results.\n",
    "\n",
    "While RAG acts as a viable supplement to LLMs, its efficiency relies heavily on the relevance and accuracy of the retrieved documents. The substantial dependence of generation on the retrieved knowledge raises notable concerns regarding the model's behavior and performance in scenarios where retrieval is not successful or the retrieved documents are inaccurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6222fa-3481-4790-8fc4-764412f9898e",
   "metadata": {},
   "source": [
    "A low-quality retriever can bring in a lot of irrelevant information. This can make it hard for models to acquire accurate knowledge and might even mislead them, causing problems like hallucinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e21d8a-6f1d-4f28-8ecd-374be75ef49d",
   "metadata": {},
   "source": [
    "Figure 1 shows how CRAG works at inference, in order to make generation more resilient. Given an input query and the retrieved documents from a retriever, CRAG uses a lightweight evaluator to estimate the relevance score of retrieved documents to the input query. This evaluation results in three confidence degrees and then triggered the corresponding actions: {Correct, Incorrect, Ambiguous}. If it's Correct, the retrieved documents are improved to be more accurate through knowledge refienment processes. This refinement operation involves knowledge decomposition, filter, and recomposition. If it's Incorrect, the retrieved documents are ignored, and web searches are used instead as complementary knowledge sources for corrections. If it's not clear whether the documents are correct or not, an action called Ambiguous is taken, combining both (Section 4.3). Once the retrieval is refined, any generative model can be used.\n",
    "\n",
    "<center><figure><img src=\"imgs/CRAG.jpg\" alt=\"drawing\" width=\"700\"/><figcaption>Fig. 1: An overview of CRAG at inference.</figcaption></figure></center>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c6d93-af3f-442b-82c6-0197250213f5",
   "metadata": {},
   "source": [
    "## Knowledge Refinement \n",
    "A retrieval is considered Correct if the confidence score of at least one retrieved document exceeds the upper threshold. This means the presence of relevant documents in the retrieval results. However, even when a relevant document is found, it may contain some irrelevant information. To extract the most important information within this document, a method called knowledge refinement is applied. This method involves decomposing and then recomposing the content of each retrieved relevant document to extract the most crucial information. Initially, each document is divided into smaller knowledge segments through heuristic rules. Then, a fine-tuned retrieval evaluator assesses the relevance score of each segment. Based on these scores, irrelevant segments are filtered out, and relevant ones are recomposed via concatenation in order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba8819-3d46-4be2-bac4-163c9842d993",
   "metadata": {},
   "source": [
    "# CRAG implementation in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4851944-e664-4c37-b252-c627f71fd655",
   "metadata": {},
   "source": [
    "We can use LangGraph of LangChain to implement CRAG. So, first let's see what [LangGraph](https://python.langchain.com/docs/langgraph) is .\n",
    "\n",
    "## LangGraph\n",
    "LLMs can be used for reasoning tasks. This can essentially be thought of as running an LLM in a for-loop. These types of systems are often called agents. Here comes LangGraph! You may want to always force an agent to call a particular tool first. You may want to have more control over agents and how tools are called. These more controlled flows are referred to as \"state machines\" in LangGraph terminology. LangGraph is a way to create these state machines by specifying them as graphs.\n",
    "\n",
    "The primary function of LangGraph is to add cycles into LLM applications. Cycles play a vital role in scenarios with agents. For example, you might repeatedly invoke an LLM within a loop to determine the next course of action.\n",
    "LangGraph is a tool designed for creating complex, stateful applications that involve multiple actors using LLMs. It is built upon LangChain and expands its capabilities by enabling the coordination of multiple chains or actors through various steps of computation in a cyclic fashion. \n",
    "It's important to note that LangGraph is not a **Directed Acyclic Graph (DAG)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a83e44-97f1-4d0e-84f4-3de1152c02cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
