{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc00f3d3-1efa-4944-badc-d1d992685f9c",
   "metadata": {},
   "source": [
    "# Continual Pre-Training vs. Fine-tuning\n",
    "\n",
    "\n",
    "In this article, we will see the difference between Fine-tuning and Continual Pre-Training. We will use Amazon Bedrock Python SDK to fine-tune and continual pre-train a foundation model with your own data. If you have a train dataset and want to adapt a base model to your domain, you can further adjust it by giving your training data. We will see how to fine-tune or continual pre-train a base model with Amazon Bedrock in this demo.\n",
    "\n",
    "You can store your data on Amazon S3 and provide the S3 bucket path while you are configuring the model customization job. You can also change the hyper parameters (like learning rate, number of epochs, and batch size) for fine-tuning. Once the fine-tuning job with your data is finished, you can deploy the model into an endpoint and use it for inference. You can use the fine-tuned model and provide your prompt to the model along with a set of model parameters. In the following, we will walk through \"continued pre-training with Amazon Bedrock\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aea827-af87-40bc-b527-83ed30646fd6",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "\n",
    "Fine-tuning and continual pre-training are both techniques used in machine learning to adapt models for specific tasks or domains. Fine-tuning involves taking a pre-trained model and adjusting its parameters using labeled data relevant to the target task, thereby tailoring it to the nuances of that particular task. This process enhances the model's effectiveness in that specific task compared to using a general-purpose pre-trained model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488cb561-5f5c-4818-a5ac-89d32047d62b",
   "metadata": {},
   "source": [
    "### Continual Pre-training \n",
    "\n",
    "On the other hand, continual pre-training entails taking an already pre-trained model and employing transfer learning to further train it on new data from a different domain. Continual pre-training allows for ongoing adaptation and refinement of the model's knowledge and performance across various tasks or domains, leveraging the previously acquired knowledge while continuously learning from new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c6b19-ca0b-431f-be47-6642725dd8eb",
   "metadata": {},
   "source": [
    "With this introduction, let's delve into the implementation in Amazon bedrock. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3c99f1-9734-4c84-b18a-0c6730bd44af",
   "metadata": {},
   "source": [
    "# Fine-tuning Process\n",
    "We will start with fine-tuning an LLM with our labeled training data. Our dataset is a public dialogue summarization dataset. We will prepare it for fine-tuning and will customize our model with the training samples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8cbf9-f2e1-4def-9861-ceb53586af44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install langchain tiktoken datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1db7254-2774-405b-82e8-4911378323e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import sagemaker\n",
    "from pprint import pprint\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd8bcb28-68e4-42db-92ca-107c24468798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Amazon Bedrock control plane including fine-tuning\n",
    "bedrock = boto3.client(service_name=\"bedrock\")\n",
    "\n",
    "# Amazon Bedrock data plane including model inference\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ae441-44a1-4b47-a229-7395bbd972e3",
   "metadata": {},
   "source": [
    "First, we should check the available models for fine-tuning. Using <code>list_foundation_models()</code>, we can list the available foundation models in Bedrock. Since we are looking for fine-tunable foundation models, we can filter the list like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f54fa09d-5a95-4aa2-9daf-4b9ae79a650d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1:0',\n",
       "  'modelId': 'amazon.titan-image-generator-v1:0',\n",
       "  'modelName': 'Titan Image Generator G1',\n",
       "  'providerName': 'Amazon',\n",
       "  'inputModalities': ['TEXT', 'IMAGE'],\n",
       "  'outputModalities': ['IMAGE'],\n",
       "  'customizationsSupported': ['FINE_TUNING'],\n",
       "  'inferenceTypesSupported': ['PROVISIONED'],\n",
       "  'modelLifecycle': {'status': 'ACTIVE'}},\n",
       " {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1:0:4k',\n",
       "  'modelId': 'amazon.titan-text-lite-v1:0:4k',\n",
       "  'modelName': 'Titan Text G1 - Lite',\n",
       "  'providerName': 'Amazon',\n",
       "  'inputModalities': ['TEXT'],\n",
       "  'outputModalities': ['TEXT'],\n",
       "  'responseStreamingSupported': True,\n",
       "  'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'],\n",
       "  'inferenceTypesSupported': ['PROVISIONED'],\n",
       "  'modelLifecycle': {'status': 'ACTIVE'}},\n",
       " {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "  'modelId': 'amazon.titan-text-express-v1:0:8k',\n",
       "  'modelName': 'Titan Text G1 - Express',\n",
       "  'providerName': 'Amazon',\n",
       "  'inputModalities': ['TEXT'],\n",
       "  'outputModalities': ['TEXT'],\n",
       "  'responseStreamingSupported': True,\n",
       "  'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'],\n",
       "  'inferenceTypesSupported': ['PROVISIONED'],\n",
       "  'modelLifecycle': {'status': 'ACTIVE'}},\n",
       " {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1:0',\n",
       "  'modelId': 'amazon.titan-embed-image-v1:0',\n",
       "  'modelName': 'Titan Multimodal Embeddings G1',\n",
       "  'providerName': 'Amazon',\n",
       "  'inputModalities': ['TEXT', 'IMAGE'],\n",
       "  'outputModalities': ['EMBEDDING'],\n",
       "  'customizationsSupported': ['FINE_TUNING'],\n",
       "  'inferenceTypesSupported': ['PROVISIONED'],\n",
       "  'modelLifecycle': {'status': 'ACTIVE'}}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock.list_foundation_models(byProvider=\"Amazon\", byCustomizationType=\"FINE_TUNING\")['modelSummaries']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bdc4ef-f1bb-4348-a990-e4abcbec6f2e",
   "metadata": {},
   "source": [
    "From the list, we can see there are two options to choose from: <code>Titan Text G1 - Express</code> and <code>Titan Text G1 - Lite</code>. For this demo, we will use the former. So, we set our base model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7649c20f-ab25-43b8-8e69-c1893f2966f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model_id = \"amazon.titan-text-express-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d64b849-db13-489a-b3a9-4656d9e05e51",
   "metadata": {},
   "source": [
    "# 3. Our dataset\n",
    "\n",
    "For this demo, we will use a public dialogue summarization dataset, \"dialogsum\" as a custom dataset to fine-tune our base model. Dialogsum is a large-scale dialogue summarization dataset has over 13,000 conversations and summaries. You can read more about it here: https://huggingface.co/datasets/knkarthick/dialogsum.\n",
    "\n",
    "Data Fields:\n",
    "\n",
    "* dialogue: text of dialogue.\n",
    "* summary: human written summary of the dialogue.\n",
    "* topic: human written topic/one liner of the dialogue.\n",
    "* id: unique file id of an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "699f8bcb-d0b7-423b-9e77-8aa4c7b30957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"knkarthick/dialogsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9114f04-0c85-46a0-812e-06d248cffacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_instruction(row):\n",
    "    row['input'] = \"Summarize the following conversation.\\n\\n\" + row['dialogue'] + \"\\n\\nSummary: \"\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26f746-9779-4adc-a99a-d6405f22b519",
   "metadata": {},
   "source": [
    "Considering fine-tuning duration and the cost, let's select only 100 of train data for fine-tuning. <code>load_dataset</code> return an instance of <code>DatasetDict</code> class. We can apply its methods to furthur refine our dataset. https://huggingface.co/docs/datasets/v2.18.0/en/package_reference/main_classes#datasets.DatasetDict.data\n",
    "First, we select 100 of the 'train' set, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84fabe9a-933e-4188-92c0-95ee87f5f773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5275f75289ef476d830feb2041249840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'output': \"Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\",\n",
       " 'input': \"Summarize the following conversation.\\n\\n#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\\n\\nSummary: \"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = dataset['train'].select(range(100))\n",
    "ds = ds.remove_columns(['id','topic'])\n",
    "ds = ds.map(convert_to_instruction)\n",
    "ds = ds.remove_columns(['dialogue'])\n",
    "ds = ds.rename_column('summary','output')\n",
    "ds.to_json('dialogsum-train-100.jsonl', index=False)\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a29831b-1b9f-4349-a372-e5672d64b9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr. Smith's getting a check-up, and Doctor Haw...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mrs Parker takes Ricky for his vaccines. Dr. P...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Person1#'s looking for a set of keys and asks...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person1#'s angry because #Person2# didn't tel...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malik invites Nikki to dance. Nikki agrees if ...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>#Person1# and #Person2# are planning the class...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Martin tells #Person1# about his experience in...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>#Person1# surveys #Person2# about #Person2#'s ...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>#Person1# and #Person2# want a place near the ...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>#Person2# buys a bouquet of violet for #Person...</td>\n",
       "      <td>Summarize the following conversation.\\n\\n#Pers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               output  \\\n",
       "0   Mr. Smith's getting a check-up, and Doctor Haw...   \n",
       "1   Mrs Parker takes Ricky for his vaccines. Dr. P...   \n",
       "2   #Person1#'s looking for a set of keys and asks...   \n",
       "3   #Person1#'s angry because #Person2# didn't tel...   \n",
       "4   Malik invites Nikki to dance. Nikki agrees if ...   \n",
       "..                                                ...   \n",
       "95  #Person1# and #Person2# are planning the class...   \n",
       "96  Martin tells #Person1# about his experience in...   \n",
       "97  #Person1# surveys #Person2# about #Person2#'s ...   \n",
       "98  #Person1# and #Person2# want a place near the ...   \n",
       "99  #Person2# buys a bouquet of violet for #Person...   \n",
       "\n",
       "                                                input  \n",
       "0   Summarize the following conversation.\\n\\n#Pers...  \n",
       "1   Summarize the following conversation.\\n\\n#Pers...  \n",
       "2   Summarize the following conversation.\\n\\n#Pers...  \n",
       "3   Summarize the following conversation.\\n\\n#Pers...  \n",
       "4   Summarize the following conversation.\\n\\n#Pers...  \n",
       "..                                                ...  \n",
       "95  Summarize the following conversation.\\n\\n#Pers...  \n",
       "96  Summarize the following conversation.\\n\\n#Pers...  \n",
       "97  Summarize the following conversation.\\n\\n#Pers...  \n",
       "98  Summarize the following conversation.\\n\\n#Pers...  \n",
       "99  Summarize the following conversation.\\n\\n#Pers...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"model_customization_data/dialogsum-train-100.jsonl\", lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b9cdb2a-d9b8-461d-ab22-b02a5132ccfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = \"model_customization_data/dialogsum-train-100.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d86ed-5e26-49c3-a982-694829c65042",
   "metadata": {},
   "source": [
    "Now we will apply json loads function on each row of the ‘json_element’ column. ‘json.loads’ is a decoder function in python which is used to decode a json object into a dictionary. ‘apply’ is a popular function in pandas that takes any function and applies to each row of the pandas dataframe or series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa5025-4b5e-4240-befa-fca8b705dd00",
   "metadata": {},
   "source": [
    "### Uploading data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4063ff70-b85b-4ffe-b444-19144a0d3690",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "# Upload input to the target location\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "prefix = \"bedrock\"\n",
    "train_s3_url = f\"s3://{bucket}/{prefix}/fine-tuning\"\n",
    "output_s3_url = f\"s3://{bucket}/{prefix}/fine-tuning/output\"\n",
    "S3Uploader().upload(\"model_customization_data/dialogsum-train-100.jsonl\", train_s3_url)\n",
    "training_data_s3 = train_s3_url + \"/dialogsum-train-100.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc70391-51dd-4897-b604-16743e3f2fd8",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "486950f0-3e76-497c-8dab-5ba2ce62dc04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job name is: fine-tuning-titan-0 - custom model name is: fine-tuned-titan-0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "job_name = f\"fine-tuning-titan-{time.localtime().tm_sec}\"\n",
    "custom_model_name = f\"fine-tuned-titan-{time.localtime().tm_sec}\"\n",
    "print(f\"job name is: {job_name} - custom model name is: {custom_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "be444679-6a8c-45a8-94a8-ef75920e4adb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'ec21b7e4-0ee9-435f-a98b-ff4cb64235e5',\n",
       "  'HTTPStatusCode': 201,\n",
       "  'HTTPHeaders': {'date': 'Wed, 10 Apr 2024 20:36:01 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '122',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'ec21b7e4-0ee9-435f-a98b-ff4cb64235e5'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:bedrock:us-east-1:609362070692:model-customization-job/amazon.titan-text-express-v1:0:8k/13y2lddfvysk'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock.create_model_customization_job(\n",
    "    customizationType=\"FINE_TUNING\",  # or CONTINUAL_PRE_TRAINING\n",
    "    jobName=job_name,\n",
    "    customModelName=custom_model_name,\n",
    "    roleArn=role,\n",
    "    baseModelIdentifier=base_model_id,\n",
    "    hyperParameters = {\n",
    "        \"epochCount\": \"10\",\n",
    "        \"batchSize\": \"1\",\n",
    "        \"learningRate\": \"0.000001\",\n",
    "        \"learningRateWarmupSteps\": \"0\"\n",
    "    },\n",
    "    trainingDataConfig={\"s3Uri\": training_data_s3},\n",
    "    outputDataConfig={\"s3Uri\": output_s3_url},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c172e0-3472-4375-8797-43dd528d1e92",
   "metadata": {},
   "source": [
    "# Check model fine-tuning progress\n",
    "\n",
    "## Attention: dpending on your resource instances the following cell may take up to 45 mins to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943da164-1e45-40cb-b211-130c6a671f9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "status = bedrock.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "\n",
    "while status == \"InProgress\":\n",
    "    print(status)\n",
    "    time.sleep(30)\n",
    "    status = bedrock.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "    \n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1da0ce-ce3c-49de-91e9-9139205421ac",
   "metadata": {},
   "source": [
    "# Performance Optimization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd430e-65f4-44c1-9842-3dbac833a590",
   "metadata": {},
   "source": [
    "## Parameter-Efficient Fine-Tuning \n",
    "One way to improve the fine-tuning process is through a method called Parameter-Efficient Fine-Tuning or PEFT for short. In contrast to fine-tuning, PEFT methods allow you to fine-tune your model with less computational resources. PEFT freezes the parameters of the pretrained model and fine-tunes a smaller set of parameters. Because we train a small number of parameters, PEFT reduces fine-tuning compute and memory requirements. PEFT techniques also reduce catastrophic forgetting, because the weights of the original model remain frozen preserving the model's knowledge. One common PEFT method is Low Ran Adaptation (LoRA)\n",
    "\n",
    "### Low Ran Adaptation (LoRA)\n",
    "Since LLMs are large, updating all model weights during training can be expensive due to GPU memory limitations. Suppose we have a large weight matrix W for a given layer. During backpropagation, we learn a ΔW matrix, which contains information on how much we want to update the original weights to minimize the loss function during training. \n",
    "\n",
    "\n",
    "Because LLMs are big, updating all the model weights during training could be expensive because of GPU memory limits. Let's say we have a large weight matrix W. During backpropagation, we update the weight matrix by ΔW in order to reduce the loss function:  \n",
    "\n",
    "$ W_{new} = W_{old} + \\Delta W $\n",
    "\n",
    "LoRA technique replaces $ \\Delta W $ with an aproximate matrices A and B in a way that:\n",
    "\n",
    "$ \\Delta W \\approx A.B $ and $ W_{new} = W_{old} + A.B $\n",
    "\n",
    "where,\n",
    "\n",
    "$ W \\in \\mathbb{R}^{d \\times d} $ and $ A \\in \\mathbb{R}^{d\\times r} $ and $ B \\in \\mathbb{R}^{r \\times d} $ \n",
    "\n",
    "$ d $ is weight matrix dimention and $ r $ is the rank of a LoRA module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d4bc62b-e6ce-41e8-8203-a5704686e090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"At what time did total solar eclipse happen in Montreal in 2024?\"\n",
    "\n",
    "body = {\n",
    "    \"inputText\": prompt,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"maxTokenCount\": 512,\n",
    "        \"stopSequences\": [],\n",
    "        \"temperature\": 1,\n",
    "        \"topP\": 0.9\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c72a8524-b634-4450-add2-df4201888da0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId=\"amazon.titan-text-express-v1\", # Amazon Titan Text model\n",
    "    body=json.dumps(body)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a733434-fae7-4656-ae74-bf6bce028875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In Montreal, Canada, a total solar eclipse will take place on June 2, 2024. This eclipse will be visible to a small portion of the country, specifically those located in the northern parts of Quebec and the southern parts of Ontario.\n"
     ]
    }
   ],
   "source": [
    "output = response['body'].read().decode('utf8')\n",
    "print(json.loads(output)['results'][0]['outputText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee1107ac-df7a-438d-8077-a7c10c077899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import WebBaseLoader, UnstructuredHTMLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c6411e9-7de3-4669-92ea-cf6d1d2de080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://blog.cirquedusoleil.com/total-solar-eclipse-montreal\"\n",
    "doc = WebBaseLoader(url).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54f44ad4-26d6-49a6-b70d-10204b59e6a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8417879-2658-4835-b3ce-b830a489daaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(doc_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d97f45c7-60b4-4aa4-97fd-55211d0ee1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents = \"\"\n",
    "for split in doc_splits:\n",
    "    content = {\"input\": split.page_content}\n",
    "    contents += json.dumps(content) + \"\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab41703a-3008-4452-89cc-85d28dc8e400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./train-continual-pretraining.jsonl\", \"w\") as file:\n",
    "    file.writelines(contents)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7a61028-63b7-4490-8c66-1b664e1c9c59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Solar Eclipse 2024 in Montreal: A Rare C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Life is a Circus\\n\\n\\nCirque du Sound\\n\\n\\n\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On April 8th, 2024, you’ll have the unique opp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Special Features and Surprises \\nIt’s no secre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Participating in the contest is straightforwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TiktokFacebookInstagramYouTube\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input\n",
       "0  Total Solar Eclipse 2024 in Montreal: A Rare C...\n",
       "1  Life is a Circus\\n\\n\\nCirque du Sound\\n\\n\\n\\n\\...\n",
       "2  On April 8th, 2024, you’ll have the unique opp...\n",
       "3  Special Features and Surprises \\nIt’s no secre...\n",
       "4  Participating in the contest is straightforwar...\n",
       "5  TiktokFacebookInstagramYouTube\\n\\n\\n\\n\\n\\n\\n\\n..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"./train-continual-pretraining.jsonl\", lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78d13897-6cf1-431d-bb67-78bef8a64074",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"./train-continual-pretraining.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b91e6616-78fd-4b85-bf2f-39b34fabefcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "s3_location = f\"s3://{sagemaker_session_bucket}/bedrock/finetuning/train-continual-pretraining.jsonl\"\n",
    "s3_output = f\"s3://{sagemaker_session_bucket}/bedrock/finetuning/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4960b61-782f-46ca-b100-6590cc7bd549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./train-continual-pretraining.jsonl to s3://sagemaker-us-east-1-609362070692/bedrock/finetuning/train-continual-pretraining.jsonl\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp train-continual-pretraining.jsonl $s3_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c73281d-18c7-4902-8092-95197221a3ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom-titan2-1712689857'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = int(time.time())\n",
    "\n",
    "job_name = \"titan2-{}\".format(timestamp)\n",
    "job_name\n",
    "\n",
    "custom_model_name = \"custom-{}\".format(job_name)\n",
    "custom_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1312659-210f-4687-89d2-fe7caf8d3b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock.create_model_customization_job(\n",
    "    customizationType=\"CONTINUED_PRE_TRAINING\", # FINE_TUNING \\ CONTINUED_PRE_TRAINING\n",
    "    jobName=job_name,\n",
    "    customModelName=custom_model_name,\n",
    "    roleArn=role,\n",
    "    baseModelIdentifier=\"amazon.titan-text-express-v1\",\n",
    "    hyperParameters = {\n",
    "        \"epochCount\": \"10\",\n",
    "        \"batchSize\": \"1\",\n",
    "        \"learningRate\": \"0.000001\"\n",
    "    },\n",
    "    trainingDataConfig={\"s3Uri\": s3_location},\n",
    "    outputDataConfig={\"s3Uri\": s3_output},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e35ad0f-2d59-4ae6-9d68-956f175dcfaa",
   "metadata": {},
   "source": [
    "Depending on your "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a5024f-29f4-457f-96b9-45bcd7c5e7d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "status = bedrock.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "\n",
    "while status == \"InProgress\":\n",
    "    print(status)\n",
    "    time.sleep(300)\n",
    "    status = bedrock.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "    \n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2d3a33-a41d-4844-b408-7a7a68c8bc66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_model_arn = bedrock.get_custom_model(modelIdentifier=custom_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581386e-d587-4e5b-af72-70e935cf7b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
